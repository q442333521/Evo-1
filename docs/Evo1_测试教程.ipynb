{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evo-1 完整测试教程\n",
    "\n",
    "本教程将带你完整体验 Evo-1 模型的各项功能，包括：\n",
    "\n",
    "1. 环境检查与模型加载\n",
    "2. 视觉-语言嵌入器测试\n",
    "3. 动作头（Flow Matching）测试\n",
    "4. 完整推理流程测试\n",
    "5. 模拟数据训练测试\n",
    "6. 可视化与分析\n",
    "\n",
    "## 准备工作\n",
    "\n",
    "确保已安装所需依赖：\n",
    "```bash\n",
    "pip install torch torchvision transformers pillow matplotlib numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境检查与模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目路径\n",
    "project_root = os.path.abspath('../Evo_1')\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"项目根目录: {project_root}\")\n",
    "print(f\"Python 版本: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查 CUDA 可用性\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"CUDA 是否可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA 版本: {torch.version.cuda}\")\n",
    "    print(f\"GPU 设备: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 数量: {torch.cuda.device_count()}\")\n",
    "    print(f\"当前 GPU 显存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from types import SimpleNamespace\n",
    "\n",
    "print(\"✓ 所有依赖导入成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 加载 Evo-1 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.Evo1 import EVO1\n",
    "\n",
    "# 模型配置\n",
    "config = {\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"vlm_name\": \"OpenGVLab/InternVL3-1B\",\n",
    "    \"action_head\": \"flowmatching\",\n",
    "    \"horizon\": 50,\n",
    "    \"per_action_dim\": 7,\n",
    "    \"action_dim\": 50 * 7,  # horizon * per_action_dim\n",
    "    \"state_dim\": 7,\n",
    "    \"embed_dim\": 896,\n",
    "    \"hidden_dim\": 1024,\n",
    "    \"num_heads\": 8,\n",
    "    \"num_layers\": 8,\n",
    "    \"dropout\": 0.0,\n",
    "    \"num_inference_timesteps\": 50,\n",
    "    \"return_cls_only\": False,\n",
    "    \"finetune_vlm\": False,\n",
    "    \"finetune_action_head\": False,\n",
    "}\n",
    "\n",
    "print(\"正在加载 Evo-1 模型...\")\n",
    "print(f\"设备: {config['device']}\")\n",
    "\n",
    "# 注意：首次运行会下载 InternVL3-1B 模型，大小约 2GB\n",
    "# 如果你已有预训练权重，可以修改 vlm_name 为本地路径\n",
    "model = EVO1(config)\n",
    "model.eval()  # 设置为评估模式\n",
    "\n",
    "print(\"✓ 模型加载成功！\")\n",
    "\n",
    "# 统计参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"总参数量: {total_params / 1e6:.2f}M\")\n",
    "print(f\"可训练参数量: {trainable_params / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 视觉-语言嵌入器测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 创建测试图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_image(text, color, size=(448, 448)):\n",
    "    \"\"\"创建带文字的测试图像\"\"\"\n",
    "    from PIL import ImageDraw, ImageFont\n",
    "    \n",
    "    # 创建彩色图像\n",
    "    img = Image.new('RGB', size, color=color)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # 添加文字\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 40)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # 计算文字位置（居中）\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "    position = ((size[0] - text_width) // 2, (size[1] - text_height) // 2)\n",
    "    \n",
    "    draw.text(position, text, fill=\"white\", font=font)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# 创建3个测试图像\n",
    "image1 = create_test_image(\"Base Camera\", (200, 100, 100))  # 红色\n",
    "image2 = create_test_image(\"Wrist Camera\", (100, 200, 100))  # 绿色\n",
    "image3 = create_test_image(\"Third Person\", (100, 100, 200))  # 蓝色\n",
    "\n",
    "# 显示图像\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(image1)\n",
    "axes[0].set_title(\"Image 1: Base Camera\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(image2)\n",
    "axes[1].set_title(\"Image 2: Wrist Camera\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(image3)\n",
    "axes[2].set_title(\"Image 3: Third Person\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ 测试图像创建成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"预处理图像为模型输入格式\"\"\"\n",
    "    # 转换为 tensor\n",
    "    image_array = np.array(image).astype(np.float32)\n",
    "    \n",
    "    # 归一化（ImageNet 统计）\n",
    "    mean = np.array([0.485, 0.456, 0.406]) * 255\n",
    "    std = np.array([0.229, 0.224, 0.225]) * 255\n",
    "    image_array = (image_array - mean) / std\n",
    "    \n",
    "    # 转换为 tensor: (H, W, C) -> (C, H, W)\n",
    "    image_tensor = torch.from_numpy(image_array).permute(2, 0, 1)\n",
    "    \n",
    "    return image_tensor\n",
    "\n",
    "# 预处理图像\n",
    "image1_tensor = preprocess_image(image1)\n",
    "image2_tensor = preprocess_image(image2)\n",
    "image3_tensor = preprocess_image(image3)\n",
    "\n",
    "# 堆叠为 batch\n",
    "images_batch = torch.stack([image1_tensor, image2_tensor, image3_tensor]).unsqueeze(0)\n",
    "print(f\"图像 batch 形状: {images_batch.shape}\")  # 应该是 (1, 3, 3, 448, 448)\n",
    "\n",
    "# 图像掩码（所有图像都有效）\n",
    "image_mask = torch.tensor([[1, 1, 1]], dtype=torch.float32)\n",
    "print(f\"图像掩码: {image_mask}\")\n",
    "\n",
    "print(\"✓ 图像预处理完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 测试视觉-语言嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移动到设备\n",
    "device = config['device']\n",
    "images_batch = images_batch.to(device)\n",
    "image_mask = image_mask.to(device)\n",
    "\n",
    "# 测试文本指令\n",
    "prompt = \"pick up the red cube and place it on the table\"\n",
    "\n",
    "print(f\"任务指令: {prompt}\")\n",
    "print(\"\\n正在生成视觉-语言嵌入...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 将图像列表准备好\n",
    "    image_list = [image1, image2, image3]\n",
    "    \n",
    "    # 获取嵌入\n",
    "    fused_tokens = model.get_vl_embeddings(\n",
    "        images=image_list,\n",
    "        image_mask=image_mask,\n",
    "        prompt=prompt,\n",
    "        return_cls_only=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n融合 token 形状: {fused_tokens.shape}\")\n",
    "    print(f\"融合 token 范围: [{fused_tokens.min():.3f}, {fused_tokens.max():.3f}]\")\n",
    "    print(f\"融合 token 均值: {fused_tokens.mean():.3f}\")\n",
    "    print(f\"融合 token 标准差: {fused_tokens.std():.3f}\")\n",
    "\n",
    "print(\"\\n✓ 视觉-语言嵌入生成成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 动作头（Flow Matching）测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 准备状态输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模拟机器人状态（7维：6个关节 + 1个夹爪）\n",
    "state = torch.tensor([\n",
    "    [0.0, -0.5, 0.3, 0.0, 0.5, 0.0, 0.5]  # 示例关节角度\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"机器人状态: {state}\")\n",
    "print(f\"状态形状: {state.shape}\")\n",
    "\n",
    "# 创建动作掩码（前6维控制关节，第7维不控制夹爪）\n",
    "action_mask = torch.tensor([\n",
    "    [[1, 1, 1, 1, 1, 1, 0] * config['horizon']]  # 重复 horizon 次\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"动作掩码形状: {action_mask.shape}\")\n",
    "print(f\"动作掩码样本: {action_mask[0, 0, :7]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 测试训练模式（前向传播）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模拟的真实动作（用于训练）\n",
    "actions_gt = torch.randn(1, config['horizon'], config['per_action_dim']).to(device)\n",
    "\n",
    "print(f\"真实动作形状: {actions_gt.shape}\")\n",
    "print(f\"真实动作样本:\\n{actions_gt[0, :3, :]}\")\n",
    "\n",
    "# 前向传播\n",
    "with torch.no_grad():\n",
    "    pred_velocity, noise = model.action_head(\n",
    "        fused_tokens=fused_tokens,\n",
    "        state=state,\n",
    "        actions_gt=actions_gt,\n",
    "        action_mask=action_mask.view(1, -1)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n预测速度形状: {pred_velocity.shape}\")\n",
    "    print(f\"噪声形状: {noise.shape}\")\n",
    "    \n",
    "    # 计算损失（MSE）\n",
    "    target = (actions_gt - noise.view(1, config['horizon'], config['per_action_dim'])).view(1, -1)\n",
    "    loss = nn.MSELoss()(pred_velocity, target)\n",
    "    \n",
    "    print(f\"\\n训练损失: {loss.item():.6f}\")\n",
    "\n",
    "print(\"\\n✓ 训练模式测试成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 测试推理模式（动作生成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"正在生成动作序列...\")\n",
    "print(f\"推理步数: {config['num_inference_timesteps']}\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    action_chunk = model.action_head.get_action(\n",
    "        fused_tokens=fused_tokens,\n",
    "        state=state,\n",
    "        action_mask=action_mask.view(1, -1)\n",
    "    )\n",
    "\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n推理时间: {inference_time:.3f} 秒\")\n",
    "print(f\"推理频率: {1/inference_time:.2f} Hz\")\n",
    "print(f\"\\n动作序列形状: {action_chunk.shape}\")\n",
    "\n",
    "# 重塑为 (horizon, per_action_dim)\n",
    "action_seq = action_chunk.view(config['horizon'], config['per_action_dim'])\n",
    "print(f\"重塑后形状: {action_seq.shape}\")\n",
    "\n",
    "# 显示前3步动作\n",
    "print(f\"\\n前3步动作:\")\n",
    "print(action_seq[:3])\n",
    "\n",
    "print(\"\\n✓ 推理模式测试成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 完整推理流程测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型的 run_inference 方法（端到端）\n",
    "print(\"测试端到端推理...\\n\")\n",
    "\n",
    "# 准备输入\n",
    "image_list = [image1, image2, image3]\n",
    "state_input = [0.0, -0.5, 0.3, 0.0, 0.5, 0.0, 0.5]\n",
    "task_prompt = \"grasp the blue object\"\n",
    "\n",
    "print(f\"任务: {task_prompt}\")\n",
    "print(f\"状态: {state_input}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    action_output = model.run_inference(\n",
    "        images=image_list,\n",
    "        image_mask=image_mask,\n",
    "        prompt=task_prompt,\n",
    "        state_input=state_input,\n",
    "        action_mask=action_mask.view(1, -1)\n",
    "    )\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n总推理时间: {total_time:.3f} 秒\")\n",
    "print(f\"动作输出形状: {action_output.shape}\")\n",
    "\n",
    "# 提取第一步动作（实际执行）\n",
    "first_action = action_output.view(config['horizon'], config['per_action_dim'])[0]\n",
    "print(f\"\\n第一步动作（待执行）:\")\n",
    "print(first_action)\n",
    "\n",
    "print(\"\\n✓ 端到端推理测试成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 可视化与分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 动作序列可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重塑动作为 (horizon, per_action_dim)\n",
    "action_trajectory = action_output.view(config['horizon'], config['per_action_dim']).cpu().numpy()\n",
    "\n",
    "# 绘制每个维度的轨迹\n",
    "fig, axes = plt.subplots(config['per_action_dim'], 1, figsize=(12, 3*config['per_action_dim']))\n",
    "\n",
    "dim_names = ['Joint 1', 'Joint 2', 'Joint 3', 'Joint 4', 'Joint 5', 'Joint 6', 'Gripper']\n",
    "\n",
    "for i in range(config['per_action_dim']):\n",
    "    axes[i].plot(action_trajectory[:, i], linewidth=2)\n",
    "    axes[i].set_ylabel(dim_names[i], fontsize=12)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 标注第一步\n",
    "    axes[i].scatter([0], [action_trajectory[0, i]], color='red', s=100, zorder=5, label='Step 1')\n",
    "    \n",
    "axes[-1].set_xlabel('Time Step', fontsize=12)\n",
    "axes[0].set_title('Predicted Action Trajectory', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ 动作轨迹可视化完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 动作分布统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个维度的分布\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(config['per_action_dim']):\n",
    "    axes[i].hist(action_trajectory[:, i], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_title(dim_names[i], fontsize=12)\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].axvline(x=action_trajectory[:, i].mean(), color='r', linestyle='--', \n",
    "                    label=f'Mean: {action_trajectory[:, i].mean():.3f}')\n",
    "    axes[i].legend(fontsize=8)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# 隐藏多余的子图\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.suptitle('Action Distribution per Dimension', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ 动作分布统计完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 动作平滑度分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算一阶差分（速度）\n",
    "velocity = np.diff(action_trajectory, axis=0)\n",
    "\n",
    "# 计算二阶差分（加速度）\n",
    "acceleration = np.diff(velocity, axis=0)\n",
    "\n",
    "# 可视化\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "# 位置\n",
    "axes[0].plot(action_trajectory[:, :6])  # 只画前6个关节\n",
    "axes[0].set_ylabel('Position', fontsize=12)\n",
    "axes[0].set_title('Joint Positions', fontsize=12, fontweight='bold')\n",
    "axes[0].legend([f'J{i+1}' for i in range(6)], loc='upper right', ncol=6)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 速度\n",
    "axes[1].plot(velocity[:, :6])\n",
    "axes[1].set_ylabel('Velocity', fontsize=12)\n",
    "axes[1].set_title('Joint Velocities (1st Derivative)', fontsize=12, fontweight='bold')\n",
    "axes[1].legend([f'J{i+1}' for i in range(6)], loc='upper right', ncol=6)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 加速度\n",
    "axes[2].plot(acceleration[:, :6])\n",
    "axes[2].set_ylabel('Acceleration', fontsize=12)\n",
    "axes[2].set_xlabel('Time Step', fontsize=12)\n",
    "axes[2].set_title('Joint Accelerations (2nd Derivative)', fontsize=12, fontweight='bold')\n",
    "axes[2].legend([f'J{i+1}' for i in range(6)], loc='upper right', ncol=6)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 计算平滑度指标（加速度的L2范数）\n",
    "smoothness = np.linalg.norm(acceleration, axis=0)\n",
    "print(\"\\n动作平滑度指标（越小越平滑）:\")\n",
    "for i in range(config['per_action_dim']):\n",
    "    print(f\"  {dim_names[i]}: {smoothness[i]:.4f}\")\n",
    "\n",
    "print(\"\\n✓ 动作平滑度分析完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模拟数据训练测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 创建模拟数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_dataset(num_samples=100):\n",
    "    \"\"\"创建合成数据集用于训练测试\"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # 随机图像\n",
    "        images = [\n",
    "            create_test_image(f\"Sample {i}\", (np.random.randint(100, 200), \n",
    "                                               np.random.randint(100, 200), \n",
    "                                               np.random.randint(100, 200)))\n",
    "            for _ in range(3)\n",
    "        ]\n",
    "        \n",
    "        # 随机状态\n",
    "        state = torch.randn(config['state_dim'])\n",
    "        \n",
    "        # 随机动作（平滑的正弦轨迹）\n",
    "        t = torch.linspace(0, 2*np.pi, config['horizon'])\n",
    "        action = torch.zeros(config['horizon'], config['per_action_dim'])\n",
    "        for j in range(config['per_action_dim']):\n",
    "            action[:, j] = torch.sin(t + np.random.rand() * 2 * np.pi) * 0.5\n",
    "        \n",
    "        # 任务描述\n",
    "        prompts = [\n",
    "            \"pick up the object\",\n",
    "            \"move to the target\",\n",
    "            \"place on the table\",\n",
    "            \"grasp the cube\",\n",
    "            \"push the button\"\n",
    "        ]\n",
    "        prompt = np.random.choice(prompts)\n",
    "        \n",
    "        dataset.append({\n",
    "            'images': images,\n",
    "            'state': state,\n",
    "            'action': action,\n",
    "            'prompt': prompt\n",
    "        })\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# 创建数据集\n",
    "print(\"创建合成数据集...\")\n",
    "train_dataset = create_synthetic_dataset(num_samples=50)\n",
    "print(f\"✓ 创建了 {len(train_dataset)} 个训练样本\")\n",
    "\n",
    "# 显示一个样本\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\n样本示例:\")\n",
    "print(f\"  任务: {sample['prompt']}\")\n",
    "print(f\"  状态形状: {sample['state'].shape}\")\n",
    "print(f\"  动作形状: {sample['action'].shape}\")\n",
    "print(f\"  图像数量: {len(sample['images'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 小规模训练测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建优化器\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-3)\n",
    "\n",
    "# 设置为训练模式\n",
    "model.train()\n",
    "\n",
    "# 训练几步\n",
    "num_steps = 10\n",
    "losses = []\n",
    "\n",
    "print(f\"开始训练 {num_steps} 步...\\n\")\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # 随机选择一个样本\n",
    "    sample = train_dataset[np.random.randint(len(train_dataset))]\n",
    "    \n",
    "    # 准备输入\n",
    "    images = sample['images']\n",
    "    state = sample['state'].unsqueeze(0).to(device)\n",
    "    actions_gt = sample['action'].unsqueeze(0).to(device)\n",
    "    prompt = sample['prompt']\n",
    "    \n",
    "    image_mask = torch.tensor([[1, 1, 1]], dtype=torch.float32).to(device)\n",
    "    action_mask = torch.ones(1, config['horizon'] * config['per_action_dim']).to(device)\n",
    "    \n",
    "    # 前向传播\n",
    "    fused_tokens = model.get_vl_embeddings(\n",
    "        images=images,\n",
    "        image_mask=image_mask,\n",
    "        prompt=prompt\n",
    "    )\n",
    "    \n",
    "    pred_velocity, noise = model.action_head(\n",
    "        fused_tokens=fused_tokens,\n",
    "        state=state,\n",
    "        actions_gt=actions_gt,\n",
    "        action_mask=action_mask\n",
    "    )\n",
    "    \n",
    "    # 计算损失\n",
    "    target = (actions_gt - noise.view(1, config['horizon'], config['per_action_dim'])).view(1, -1)\n",
    "    loss = nn.MSELoss()(pred_velocity, target)\n",
    "    \n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    print(f\"Step {step+1}/{num_steps}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "print(\"\\n✓ 训练测试完成！\")\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, marker='o', linewidth=2)\n",
    "plt.xlabel('Training Step', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training Loss Curve', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n初始损失: {losses[0]:.6f}\")\n",
    "print(f\"最终损失: {losses[-1]:.6f}\")\n",
    "print(f\"损失降低: {(losses[0] - losses[-1]) / losses[0] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 训练后推理测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换回评估模式\n",
    "model.eval()\n",
    "\n",
    "# 测试样本\n",
    "test_sample = train_dataset[0]\n",
    "\n",
    "print(f\"测试任务: {test_sample['prompt']}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    action_pred = model.run_inference(\n",
    "        images=test_sample['images'],\n",
    "        image_mask=torch.tensor([[1, 1, 1]], dtype=torch.float32).to(device),\n",
    "        prompt=test_sample['prompt'],\n",
    "        state_input=test_sample['state'].tolist(),\n",
    "        action_mask=torch.ones(1, config['horizon'] * config['per_action_dim']).to(device)\n",
    "    )\n",
    "\n",
    "# 对比预测与真实动作\n",
    "action_pred_seq = action_pred.view(config['horizon'], config['per_action_dim']).cpu().numpy()\n",
    "action_gt_seq = test_sample['action'].numpy()\n",
    "\n",
    "# 可视化对比\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "# 选择3个维度进行可视化\n",
    "dims_to_plot = [0, 2, 4]\n",
    "\n",
    "for idx, dim in enumerate(dims_to_plot):\n",
    "    axes[idx].plot(action_gt_seq[:, dim], label='Ground Truth', linewidth=2, linestyle='--')\n",
    "    axes[idx].plot(action_pred_seq[:, dim], label='Predicted', linewidth=2)\n",
    "    axes[idx].set_ylabel(dim_names[dim], fontsize=12)\n",
    "    axes[idx].legend(fontsize=10)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Time Step', fontsize=12)\n",
    "axes[0].set_title('Predicted vs Ground Truth Actions', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 计算预测误差\n",
    "mse = np.mean((action_pred_seq - action_gt_seq) ** 2)\n",
    "mae = np.mean(np.abs(action_pred_seq - action_gt_seq))\n",
    "\n",
    "print(f\"\\n预测误差:\")\n",
    "print(f\"  MSE: {mse:.6f}\")\n",
    "print(f\"  MAE: {mae:.6f}\")\n",
    "\n",
    "print(\"\\n✓ 训练后推理测试完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 性能分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 推理速度基准测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# 预热\n",
    "for _ in range(5):\n",
    "    with torch.no_grad():\n",
    "        _ = model.run_inference(\n",
    "            images=test_sample['images'],\n",
    "            image_mask=torch.tensor([[1, 1, 1]], dtype=torch.float32).to(device),\n",
    "            prompt=test_sample['prompt'],\n",
    "            state_input=test_sample['state'].tolist(),\n",
    "            action_mask=torch.ones(1, config['horizon'] * config['per_action_dim']).to(device)\n",
    "        )\n",
    "\n",
    "# 基准测试\n",
    "num_iterations = 50\n",
    "times = []\n",
    "\n",
    "print(f\"运行 {num_iterations} 次推理...\")\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _ = model.run_inference(\n",
    "            images=test_sample['images'],\n",
    "            image_mask=torch.tensor([[1, 1, 1]], dtype=torch.float32).to(device),\n",
    "            prompt=test_sample['prompt'],\n",
    "            state_input=test_sample['state'].tolist(),\n",
    "            action_mask=torch.ones(1, config['horizon'] * config['per_action_dim']).to(device)\n",
    "        )\n",
    "    \n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    times.append(time.time() - start)\n",
    "\n",
    "times = np.array(times)\n",
    "\n",
    "print(f\"\\n推理性能统计:\")\n",
    "print(f\"  平均时间: {times.mean()*1000:.2f} ms\")\n",
    "print(f\"  标准差: {times.std()*1000:.2f} ms\")\n",
    "print(f\"  最小时间: {times.min()*1000:.2f} ms\")\n",
    "print(f\"  最大时间: {times.max()*1000:.2f} ms\")\n",
    "print(f\"  平均频率: {1/times.mean():.2f} Hz\")\n",
    "\n",
    "# 绘制时间分布\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(times * 1000, marker='o', markersize=3)\n",
    "plt.axhline(y=times.mean()*1000, color='r', linestyle='--', label=f'Mean: {times.mean()*1000:.2f} ms')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Inference Time (ms)')\n",
    "plt.title('Inference Time per Iteration')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(times * 1000, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=times.mean()*1000, color='r', linestyle='--', label=f'Mean: {times.mean()*1000:.2f} ms')\n",
    "plt.xlabel('Inference Time (ms)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Inference Time Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ 性能基准测试完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 显存占用分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # 清空缓存\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    # 运行推理\n",
    "    with torch.no_grad():\n",
    "        _ = model.run_inference(\n",
    "            images=test_sample['images'],\n",
    "            image_mask=torch.tensor([[1, 1, 1]], dtype=torch.float32).to(device),\n",
    "            prompt=test_sample['prompt'],\n",
    "            state_input=test_sample['state'].tolist(),\n",
    "            action_mask=torch.ones(1, config['horizon'] * config['per_action_dim']).to(device)\n",
    "        )\n",
    "    \n",
    "    # 获取显存统计\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "    max_allocated = torch.cuda.max_memory_allocated() / 1024**3\n",
    "    \n",
    "    print(\"GPU 显存占用:\")\n",
    "    print(f\"  当前分配: {allocated:.3f} GB\")\n",
    "    print(f\"  保留显存: {reserved:.3f} GB\")\n",
    "    print(f\"  峰值分配: {max_allocated:.3f} GB\")\n",
    "    \n",
    "    # 可视化\n",
    "    labels = ['Allocated', 'Reserved', 'Peak']\n",
    "    values = [allocated, reserved, max_allocated]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(labels, values, color=['blue', 'orange', 'red'], alpha=0.7, edgecolor='black')\n",
    "    plt.ylabel('Memory (GB)', fontsize=12)\n",
    "    plt.title('GPU Memory Usage', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 0.1, f\"{v:.3f} GB\", ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"CPU 模式，无显存统计\")\n",
    "\n",
    "print(\"\\n✓ 显存分析完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\" \" * 25 + \"Evo-1 测试总结\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n【模型信息】\")\n",
    "print(f\"  模型名称: Evo-1\")\n",
    "print(f\"  总参数量: {total_params / 1e6:.2f}M\")\n",
    "print(f\"  视觉-语言模型: InternVL3-1B\")\n",
    "print(f\"  动作头: Flow Matching\")\n",
    "\n",
    "print(\"\\n【配置参数】\")\n",
    "print(f\"  Horizon: {config['horizon']}\")\n",
    "print(f\"  动作维度: {config['per_action_dim']}\")\n",
    "print(f\"  状态维度: {config['state_dim']}\")\n",
    "print(f\"  推理步数: {config['num_inference_timesteps']}\")\n",
    "\n",
    "print(\"\\n【性能指标】\")\n",
    "if 'times' in locals():\n",
    "    print(f\"  平均推理时间: {times.mean()*1000:.2f} ms\")\n",
    "    print(f\"  推理频率: {1/times.mean():.2f} Hz\")\n",
    "if torch.cuda.is_available() and 'allocated' in locals():\n",
    "    print(f\"  显存占用: {allocated:.3f} GB\")\n",
    "\n",
    "print(\"\\n【测试结果】\")\n",
    "print(\"  ✓ 视觉-语言嵌入测试: 通过\")\n",
    "print(\"  ✓ 动作头训练模式测试: 通过\")\n",
    "print(\"  ✓ 动作头推理模式测试: 通过\")\n",
    "print(\"  ✓ 端到端推理测试: 通过\")\n",
    "print(\"  ✓ 训练流程测试: 通过\")\n",
    "print(\"  ✓ 性能基准测试: 通过\")\n",
    "\n",
    "print(\"\\n【功能验证】\")\n",
    "print(\"  ✓ 多视角图像输入\")\n",
    "print(\"  ✓ 自然语言指令理解\")\n",
    "print(\"  ✓ 机器人状态编码\")\n",
    "print(\"  ✓ 动作序列生成\")\n",
    "print(\"  ✓ 动作掩码支持\")\n",
    "print(\"  ✓ 平滑轨迹生成\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \" * 20 + \"所有测试已成功完成！\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 下一步\n",
    "\n",
    "完成本教程后，你可以：\n",
    "\n",
    "1. **使用真实数据训练**：按照中文使用手册准备数据集并训练\n",
    "2. **在仿真环境中评估**：运行 Meta-World 或 LIBERO 评估\n",
    "3. **部署到真实机器人**：参考 xArm6 客户端示例实现自己的机器人控制\n",
    "4. **微调模型**：在特定任务上进行 fine-tuning\n",
    "5. **优化性能**：尝试降低推理时间或减小模型大小\n",
    "\n",
    "## 10. 参考资源\n",
    "\n",
    "- **原理说明**: `docs/原理说明.md`\n",
    "- **使用手册**: `docs/中文使用手册.md`\n",
    "- **论文**: https://arxiv.org/abs/2511.04555\n",
    "- **GitHub**: https://github.com/MINT-SJTU/Evo-1\n",
    "- **模型**: https://huggingface.co/MINT-SJTU/Evo-1\n",
    "\n",
    "---\n",
    "\n",
    "*祝你使用愉快！如有问题，欢迎提 Issue。*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
