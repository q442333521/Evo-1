# Evo-1 文档中心

欢迎来到 Evo-1 的完整中文文档！本目录包含详细的原理说明、使用手册和测试教程。

## 📚 文档列表

### 1. [原理说明.md](./原理说明.md) - 技术原理详解

**适合人群**：研究人员、算法工程师、深度学习爱好者

**内容概览**：
- 项目概述与核心贡献
- 技术架构详解
  - 视觉-语言嵌入器（InternVL3）
  - 流匹配动作头（Flow Matching Action Head）
  - 多具身体系统支持
- 训练策略（两阶段训练）
- 数据格式说明（LeRobot v2.1）
- 推理部署架构
- 评估基准（Meta-World、LIBERO、RoboTwin）
- 与其他VLA模型的比较
- 技术亮点总结

**关键亮点**：
- 深入解析流匹配（Flow Matching）原理
- 详细的数学公式和伪代码
- Transformer架构详解
- 动作生成的完整流程

### 2. [中文使用手册.md](./中文使用手册.md) - 完整操作指南

**适合人群**：实践者、机器人工程师、应用开发者

**内容概览**：
- 快速开始（30秒体验）
- 环境安装（Evo-1、Meta-World、LIBERO）
- 模型下载（HuggingFace）
- 数据准备
  - LeRobot格式说明
  - 下载示例数据集
  - 转换自定义数据集
- 模型训练
  - 阶段一：动作专家训练
  - 阶段二：全模型微调
  - 恢复训练
- 模型评估
  - Meta-World评估
  - LIBERO评估
- 实际部署
  - 服务器-客户端架构
  - 观测数据构造
  - 动作执行
  - xArm6部署示例
- 常见问题解答
- 进阶使用技巧

**实用工具**：
- 完整的命令行示例
- 配置文件模板
- 常见错误排查
- 性能优化建议

### 3. [Evo1_测试教程.ipynb](./Evo1_测试教程.ipynb) - 交互式测试教程

**适合人群**：所有用户，尤其是初学者

**内容概览**：
- 环境检查与模型加载
- 视觉-语言嵌入器测试
- 动作头（Flow Matching）测试
- 完整推理流程测试
- 模拟数据训练测试
- 可视化与分析
  - 动作序列可视化
  - 动作分布统计
  - 动作平滑度分析
- 性能分析
  - 推理速度基准测试
  - 显存占用分析

**交互特性**：
- 可直接在 Jupyter Notebook 中运行
- 包含完整的可视化代码
- 逐步引导式教学
- 实时查看测试结果

## 🚀 快速导航

### 我想了解原理
→ 阅读 [原理说明.md](./原理说明.md)

### 我想快速上手
→ 阅读 [中文使用手册.md](./中文使用手册.md) 的"快速开始"部分

### 我想测试功能
→ 运行 [Evo1_测试教程.ipynb](./Evo1_测试教程.ipynb)

### 我想训练模型
→ 参考 [中文使用手册.md](./中文使用手册.md) 第6章"模型训练"

### 我想部署到机器人
→ 参考 [中文使用手册.md](./中文使用手册.md) 第8章"实际部署"

### 我遇到了问题
→ 查看 [中文使用手册.md](./中文使用手册.md) 第9章"常见问题"

## 📖 推荐阅读顺序

### 初学者路线

1. **了解项目** - 阅读主 README.md
2. **快速体验** - 按照"中文使用手册"的快速开始部分操作
3. **动手实践** - 运行 Jupyter 测试教程
4. **深入学习** - 阅读原理说明文档
5. **实际应用** - 参考使用手册进行训练和部署

### 研究人员路线

1. **理解原理** - 阅读原理说明文档
2. **查看代码** - 研究核心模块实现
3. **复现实验** - 按照使用手册进行评估
4. **改进创新** - 基于理解进行改进

### 工程师路线

1. **环境搭建** - 按照使用手册安装环境
2. **功能测试** - 运行 Jupyter 测试教程
3. **数据准备** - 转换自己的数据集
4. **模型训练** - 在自己的数据上训练
5. **实际部署** - 部署到目标机器人

## 🔗 相关资源

### 论文与代码
- **论文**: [arXiv:2511.04555](https://arxiv.org/abs/2511.04555)
- **GitHub**: [https://github.com/MINT-SJTU/Evo-1](https://github.com/MINT-SJTU/Evo-1)
- **项目主页**: [https://mint-sjtu.github.io/Evo-1.io/](https://mint-sjtu.github.io/Evo-1.io/)

### 模型与数据
- **HuggingFace 模型**: [MINT-SJTU/Evo-1](https://huggingface.co/MINT-SJTU/Evo-1)
- **HuggingFace 数据集**: [Evo1_MetaWorld](https://huggingface.co/datasets/MINT-SJTU/Evo1_MetaWorld)

### 基础知识
- **InternVL3**: 视觉-语言预训练模型
- **Flow Matching**: 连续归一化流方法
- **LeRobot**: 机器人数据格式标准
- **Meta-World**: 机器人操作基准测试
- **LIBERO**: 长期机器人任务基准

## 📝 文档维护

### 版本信息
- **文档版本**: v1.0
- **创建日期**: 2025-11-11
- **适用模型**: Evo-1 (77M 参数)
- **对应代码**: commit [查看最新commit]

### 更新日志
- **2025-11-11**: 创建完整中文文档体系
  - 添加原理说明文档
  - 添加中文使用手册
  - 添加 Jupyter 测试教程
  - 添加文档索引

### 贡献指南
如果你发现文档中的错误或有改进建议：

1. 提交 Issue: [GitHub Issues](https://github.com/MINT-SJTU/Evo-1/issues)
2. 提交 Pull Request
3. 联系项目维护者

## 💡 使用建议

### 建议 1: 理论结合实践
在阅读原理说明的同时，建议运行 Jupyter 教程中的相应代码，加深理解。

### 建议 2: 循序渐进
不要急于训练大规模模型，先在小数据集上验证流程。

### 建议 3: 保存实验记录
记录每次实验的配置和结果，方便后续对比和调试。

### 建议 4: 善用可视化
使用 Jupyter 教程中的可视化代码分析模型行为。

### 建议 5: 社区交流
遇到问题时，先查阅常见问题，然后在 GitHub 上提问。

## ⚠️ 注意事项

1. **环境依赖**: 确保安装了所有必需的依赖包
2. **GPU要求**: 推荐使用 RTX 3090 或更好的 GPU
3. **显存需求**: 至少需要 24GB 显存用于训练
4. **数据格式**: 严格遵循 LeRobot v2.1 格式
5. **检查点路径**: 修改配置文件中的路径为你的实际路径

## 🎯 学习目标

完成所有文档学习后，你将能够：

- ✅ 理解 Evo-1 的技术原理和创新点
- ✅ 独立搭建训练和评估环境
- ✅ 在自己的数据集上训练模型
- ✅ 在仿真环境中评估模型性能
- ✅ 将模型部署到真实机器人
- ✅ 调试和优化模型性能
- ✅ 进行创新性的研究和开发

## 📞 获取帮助

### 在线资源
- **GitHub Discussions**: 技术讨论
- **GitHub Issues**: 问题报告
- **项目主页**: 最新动态

### 文档反馈
如果你对文档有任何意见或建议，欢迎：
- 提交 Issue
- 发送邮件给维护者
- 加入微信交流群（见主 README）

---

**祝你学习愉快，使用顺利！**

*如有任何问题，请随时联系我们。*

---

*文档由上海交通大学 MINT 实验室维护*
